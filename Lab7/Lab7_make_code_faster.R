renv::init() # инициализация виртуального окружения
renv::install() # установка библиотеки из CRAN
renv::snapshot() # делаем снимок версий библиотек в нашем виртуальном окружении
# фиксируем этот список в .lock-файле для возможности восстановления
# renv::restore() # команда отктиться к предыдушему удачному обновления библиотек

# ------------------- 
# Лабораторная работа №7:
# Улучшение быстродействия кода R.

# Факторы, которые влияют на скорость работы программы:
# R - язык интерпретируемый
# все объекты в сеансе R хранятся в оперативной памяти. Ограничение - 2^31 -1 байт для размера любого объекта
# по-факту, при работе с данными вы ограничены размером RAM вашего ПК

# Что можно сделать, чтобы ускорить ваш код:

# Профилирование времени исполнения кусков кода, написание более лаконичных конструкций
# Оптимизация посредством векторизации
# Применение компиляции в байт-код
# Написание ключевых частей кода, создающих интенсивную нагрузку на процессор на компилируемом языке (С/С++)
# Написание кода на одной из разновидности параллельного R

# Векторизация vs.цикла for, сравните:

z <- x + y # такая операция быстрее цикла

for (i in 1:length(x)) z[i] <- x[i] + y[i]

# замерим хронометраж исполнения

x <- runif(1000000)
y <- runif(1000000)
z <- vector(length = 1000000)
system.time(z <- x + y)

# теперь цикл
system.time(for (i in 1:length(x)) z[i] <- x[i] + y[i])
# получилось гораздо дольше!

# почему?
# цикл for, на самом деле состоит из многочисленных вызовов функций:
# ":" - это ф-ия ":"(1,10)
# операции индексирования - это вызов ф-ии "[" для 2х чтений и "[<-" для записи

# примеры векторизованных функций, которые могут заменить цикл:
# ifelse(), which(), where(), any(), all(), cumsum(), cumprod(), rowSums(), colSums(), combin(), outer(), lower.tri(), upper.tri(), expand.grid()

# функции семейства apply() устраняют внешний цикл, но реализованы не на языке C, а на языке R. Поэтому не так быстры как можно подумать.

# Рассмотрим пример ускорения моделирования методом Монте-Карло
# загрузим 2а файла мини-скриптов из рабочей папки Lab7 и сравним скорость:
setwd() # укажите путь до файлов
system.time(source("Maxnorm1.R")) # базовый вариант

system.time(source("Maxnorm2.R")) # улучшенный
# почему быстрее?
# все слуайные переменные генерируются одновременно в матрице xymat c одной парой XY на строку
# затем мы находим все значения max(X,Y), сохраняем эти значения в maxs после чего просто вызываем mean

# обратите внимание - повышения скорости происходит за счет увеличения затрат памяти. Это типичная дилемма.
# Кроме того, критичное влияние на скорость исполнения кода оказывает реализация примененного алгоритма. Самостоятельно прочитайте про нотацию O(N).

# Функциональное программирование и работа с памятью
z <- c()
z[3] <- 8 # такое присваивание сложнее, чем можно подумать
# в действительности, оно реализуется так:
tracemem(z) 

z <- "[<-"(z,3,value=8)

# здесь создается внутренняя копия z, элемент 3 копии заменяется на 8, а полученный вектор снова присваивается z.
# это означает, что в z хранится ссылка на копию. На первый взгляд, меняется всего один элемент, но пересчитывается весь вектор!

tracemem(z) 

# обратите внимание на то, что адреса в памяти изменились - смотрите вывод ф-ии tracemem() до и после

# предотвращайте копирование в памяти:

m <- 5000
n <- 1000
z <- list()
for(i in 1:m) z[[i]] <- sample(1:10, n, replace = T)
system.time(
  for (i in 1:m) z[[i]][3] <- 8
  )

# и матричный вариант того же самого кода:
z <- matrix(
  sample(1:10, m*n, replace = T),
  nrow = m
)

system.time(z[,3] <- 8)

# в списковой версии происходит копирование в памяти при каждой итерации цикла, тогда как в матричной - только один раз

# использование ф-ии Rprof() для профилирования затрат времени кода:
x <- runif(1000000)
Rprof()
invisible(power(x))
Rprof(NULL)
summaryRprof()

# Компиляция в байт-код:
x <- runif(1000000)
y <- runif(1000000)
z <- x + y # работает быстрее цикла
system.time(z <- x + y)

z <- vector(length = 1000000)
system.time(for (i in 1:length(x)) z[i] <- x[i] + y[i])

# но если обернуть цикл в функцию и скомпилировать ее в байт-код, будет быстрее
library(compiler)
f <- function() for (i in 1:length(x)) z[i] <<- x[i] + y[i]
cf <- cmpfun(f)
system.time(cf())


# Если данные не помещаются в память?
# допустим, дата-сет состоит из 1М строк
# read.table(skip = 0) - при первом чтении
# read.table(skip = 100000) - при втором чтении
# и так далее - каждый раз мы читаем данный по блокам, пропуская ненужные куски

# Если этот подход не помог, рассмотрите возможность работы с пакетом RMySQL, который предоставляет R интерфейс к SQL БД
# Если и это не помогло - присмотритесь к пакетам biglm (выполняет регрессионный анализ для очень больших наборов данных), пакетам ff (обходит ограничения памяти, сохраняя данные на диске), 
# bigmemory (то же самое, но не только на диске, но и в основной памяти)
